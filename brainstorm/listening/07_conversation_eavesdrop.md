# Conversation Eavesdrop

AI generates a multi-speaker conversation that the learner "overhears." They must answer questions about who said what, speaker intent, and implied meaning — training pragmatic and inferential listening, not just word recognition.

## Why it's novel
Most listening exercises test literal comprehension (what was said). This tests pragmatic comprehension (who said it, why, what was implied) — a higher-order skill rarely trained explicitly but critical for real-world communication.

## Why it's effective
Real-world listening is rarely one-on-one with clear turn-taking. Multi-speaker comprehension, speaker attribution, and inference are the skills that separate classroom listeners from competent real-world listeners. Training these explicitly accelerates the transition.

## How AI enables it
- LLM generates multi-character dialogues with distinct speaker voices, personalities, and conversational goals including subtext and implication
- TTS produces distinct voices for each speaker
- LLM generates comprehension questions that target pragmatic and inferential understanding, not just factual recall
- LLM evaluates open-ended answers about speaker intent and implied meaning

## Progress Tracking & Assessment

Progress is measured across three pragmatic listening skills: speaker attribution, intent recognition, and inference.

### 1. Pragmatic Skill Breakdown

Each eavesdrop session tests all three skills independently.

**Example** (German speaker learning English, workplace curriculum):

A 3-person English conversation: two colleagues (Anna, Thomas) and their manager (Ms. Weber) discussing a missed project deadline.

Questions and learner performance:
> Speaker attribution: "Who suggested extending the deadline?" — Learner said Thomas. Correct. ✓
> Intent recognition: "Why did Anna mention her workload?" — Learner said "to complain." System: partial credit — Anna was deflecting blame, not just complaining. The key phrase was "I also had the other project on my plate." ◐
> Inference: "Will Ms. Weber approve the extension?" — Learner said "yes." System: she didn't say yes explicitly, but her tone softened and she asked about a revised timeline, implying openness. ✓

Score: Attribution 100%, Intent 50%, Inference 100%.

Over time: "Your attribution is consistently strong. Intent recognition is your weak point — you're catching what people say but missing why they say it."

### 2. Speaker Count Progression

As the learner improves, conversations add more speakers and more complex social dynamics.

**Example:**

> Level 1: 2 speakers, explicit disagreement. Avg score: 85%.
> Level 2: 3 speakers, one speaker has a hidden agenda. Avg score: 65%.
> Level 3: 4 speakers, shifting alliances, sarcasm. Avg score: — (locked)

"You're handling 3-speaker conversations. Unlock Level 3 by hitting 75% on intent recognition."

### 3. Cultural Pragmatics Tracking

For languages where indirectness and politeness levels carry meaning, the system tracks whether the learner picks up on culture-specific cues.

**Example:**

In an English workplace eavesdrop, the manager says "That's an interesting idea. Let me think about it and get back to you."
> Question: "Does the manager approve the proposal?"
> Learner says "Yes, she likes it — she said it's interesting." System: In English workplace culture, "interesting" combined with "let me get back to you" is often a polite way to shelve an idea without directly saying no.

"Cultural pragmatics accuracy: 30%. You're interpreting English politeness literally. This is common — 'interesting' and 'let me think about it' often signal soft rejection in professional English. We'll increase exposure to indirect refusal patterns."
